{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQddW7h0v4JT"
      },
      "source": [
        "# Combination PF and CNN Methods On MNIST Dataset\n",
        "\n",
        "# Step 1: Creating LeNet-5 CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jo40iqaTSStl",
        "outputId": "0067e402-bc14-461b-91fc-08d1a144ba00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,840</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m6\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │           \u001b[38;5;34m2,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                 │          \u001b[38;5;34m30,840\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │          \u001b[38;5;34m10,164\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m850\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,426</span> (173.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,426\u001b[0m (173.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,426</span> (173.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,426\u001b[0m (173.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8179 - loss: 0.6300 - val_accuracy: 0.9678 - val_loss: 0.1140\n",
            "Epoch 2/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.9663 - loss: 0.1094 - val_accuracy: 0.9744 - val_loss: 0.0877\n",
            "Epoch 3/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.9778 - loss: 0.0735 - val_accuracy: 0.9827 - val_loss: 0.0607\n",
            "Epoch 4/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.9842 - loss: 0.0533 - val_accuracy: 0.9813 - val_loss: 0.0650\n",
            "Epoch 5/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.9867 - loss: 0.0424 - val_accuracy: 0.9843 - val_loss: 0.0550\n",
            "Epoch 6/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9895 - loss: 0.0354 - val_accuracy: 0.9838 - val_loss: 0.0566\n",
            "Epoch 7/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - accuracy: 0.9904 - loss: 0.0311 - val_accuracy: 0.9867 - val_loss: 0.0461\n",
            "Epoch 8/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9915 - loss: 0.0279 - val_accuracy: 0.9860 - val_loss: 0.0495\n",
            "Epoch 9/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 29ms/step - accuracy: 0.9920 - loss: 0.0247 - val_accuracy: 0.9880 - val_loss: 0.0429\n",
            "Epoch 10/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.9935 - loss: 0.0201 - val_accuracy: 0.9877 - val_loss: 0.0451\n",
            "Epoch 11/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.9939 - loss: 0.0172 - val_accuracy: 0.9899 - val_loss: 0.0395\n",
            "Epoch 12/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - accuracy: 0.9953 - loss: 0.0154 - val_accuracy: 0.9859 - val_loss: 0.0486\n",
            "Epoch 13/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0136 - val_accuracy: 0.9899 - val_loss: 0.0405\n",
            "Epoch 14/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9960 - loss: 0.0116 - val_accuracy: 0.9883 - val_loss: 0.0448\n",
            "Epoch 15/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 28ms/step - accuracy: 0.9963 - loss: 0.0119 - val_accuracy: 0.9872 - val_loss: 0.0478\n",
            "Epoch 16/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.9871 - val_loss: 0.0501\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9879 - loss: 0.0373\n",
            "Test Loss: 0.0309\n",
            "Test Accuracy: 0.9903\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Shape of corrected train_features_1600: (60000, 10)\n",
            "Shape of corrected test_features_1600: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Input, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Normalize the images to have values between 0 and 1\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "# Build the LeNet-5 model\n",
        "cnn_model = Sequential([\n",
        "    Input(shape=(28, 28, 1)),\n",
        "    Conv2D(6, kernel_size=(5, 5), activation='relu'),\n",
        "    AveragePooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "    AveragePooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(120, activation='relu'),\n",
        "    Dense(84, activation='relu'),\n",
        "    Dense(10, activation='softmax')  # Classification layer for MNIST\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "cnn_model.summary()\n",
        "\n",
        "# Compile the model with Adam optimizer and an appropriate learning rate\n",
        "cnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Implement early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "cnn_model.fit(train_images, train_labels, validation_split=0.2, epochs=20, batch_size=64, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = cnn_model.evaluate(test_images, test_labels)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Ensure the model is called once before extracting features\n",
        "_ = cnn_model.predict(train_images[:1])\n",
        "\n",
        "# Get the corrected 1600D features from the CNN\n",
        "train_features_10 = cnn_model.predict(train_images)\n",
        "test_features_10 = cnn_model.predict(test_images)\n",
        "print(f'Shape of corrected train_features_1600: {train_features_10.shape}')\n",
        "print(f'Shape of corrected test_features_1600: {test_features_10.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12lfSlXmKVIT"
      },
      "source": [
        "# Conclusion part1:\n",
        "We reproduced a CNN model on the MNIST dataset with an accuracy of 99%. Now, we have 60,000 training images and 10,000 test images converted to 10-dimensional vectors. We will use these vectors to feed into the Random Forest model and apply the Professional Forest methodology to see the outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "972KqiI_9X7B"
      },
      "source": [
        "# Step 2: Create RF Model, Train, Test, and Evaluate it + Using RandomizedSearchCV to Create Best Model and Evaluate it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X5JKlOLbd8n",
        "outputId": "e2880187-dcbd-49e7-d468-62649a452e81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Model Accuracy: 0.9905\n",
            "Precision: 0.9904, Recall: 0.9903, F1 Score: 0.9904\n",
            "Fitting 2 folds for each of 30 candidates, totalling 60 fits\n",
            "Best parameters found by RandomizedSearchCV: {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 189}\n",
            "Random Forest Model Accuracy after RandomizedSearchCV: 0.9901\n",
            "Precision: 0.9900, Recall: 0.9899, F1 Score: 0.9899\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "import numpy as np\n",
        "\n",
        "# Create and train the Random Forest classifier with 10D features\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(train_features_10, train_labels)\n",
        "\n",
        "# Predict and evaluate\n",
        "predictions = rf_model.predict(test_features_10)\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "precision = precision_score(test_labels, predictions, average='macro')\n",
        "recall = recall_score(test_labels, predictions, average='macro')\n",
        "f1 = f1_score(test_labels, predictions, average='macro')\n",
        "print(f'Random Forest Model Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
        "\n",
        "# Define parameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 200),\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': randint(2, 5),\n",
        "    'min_samples_leaf': randint(1, 3),\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Sampling a smaller subset of the dataset\n",
        "sample_size = 10000\n",
        "train_sample_indices = np.random.choice(train_features_10.shape[0], sample_size, replace=False)\n",
        "train_features_sample = train_features_10[train_sample_indices]\n",
        "train_labels_sample = train_labels[train_sample_indices]\n",
        "\n",
        "# Initialize RandomizedSearchCV with the classifier and parameter distributions\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=30, cv=2, n_jobs=-1, verbose=2, random_state=42)\n",
        "\n",
        "# Fit RandomizedSearchCV to the sampled training data\n",
        "random_search.fit(train_features_sample, train_labels_sample)\n",
        "\n",
        "# Get the best parameters and the best model\n",
        "best_params = random_search.best_params_\n",
        "best_rf_model = random_search.best_estimator_\n",
        "print(f'Best parameters found by RandomizedSearchCV: {best_params}')\n",
        "\n",
        "# Predict and evaluate the best model on the test data\n",
        "optimized_predictions = best_rf_model.predict(test_features_10)\n",
        "optimized_accuracy = accuracy_score(test_labels, optimized_predictions)\n",
        "optimized_precision = precision_score(test_labels, optimized_predictions, average='macro')\n",
        "optimized_recall = recall_score(test_labels, optimized_predictions, average='macro')\n",
        "optimized_f1 = f1_score(test_labels, optimized_predictions, average='macro')\n",
        "print(f'Random Forest Model Accuracy after RandomizedSearchCV: {optimized_accuracy:.4f}')\n",
        "print(f'Precision: {optimized_precision:.4f}, Recall: {optimized_recall:.4f}, F1 Score: {optimized_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVpwMi27PgGb"
      },
      "source": [
        "# output:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChJlth0bPsJ7"
      },
      "source": [
        "Random Forest Model Accuracy: 0.9905\n",
        "Precision: 0.9904, Recall: 0.9903, F1 Score: 0.9904\n",
        "Fitting 2 folds for each of 30 candidates, totalling 60 fits\n",
        "Best parameters found by RandomizedSearchCV: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 127}\n",
        "Random Forest Model Accuracy after RandomizedSearchCV: 0.9901\n",
        "Precision: 0.9900, Recall: 0.9899, F1 Score: 0.9899\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyKuUrftNR1j"
      },
      "source": [
        "# Conclusion part2:\n",
        "By combining a robust CNN model with a Random Forest model, we achieved a highly accurate model for predicting on the MNIST dataset. The Random Forest model alone achieved an accuracy of 98.95%. However, after applying RandomizedSearchCV and using the best parameters, we found that the model's performance did not significantly improve, resulting in a slight decrease in accuracy to 98.91%.\n",
        "\n",
        "Despite this, the model still demonstrates strong performance and robustness. The use of RandomizedSearchCV helps to identify the best parameters, but in this case, the initial model configuration already provided excellent results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4iQxgUKdzBP"
      },
      "source": [
        "# Step 3: Professional Forest (PF) Methodology\n",
        "# Step 3-1: Create Primary Forest with 2000 Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89CCmj3ed0lv",
        "outputId": "1635cddf-7ca1-481c-dee5-cd7f86e81ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Primary Forest Model Accuracy: 0.9907\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Create and train the primary forest with 2000 trees\n",
        "primary_forest = RandomForestClassifier(n_estimators=2000, random_state=42)\n",
        "primary_forest.fit(train_features_10, train_labels)\n",
        "\n",
        "# Evaluate the primary forest model\n",
        "primary_predictions = primary_forest.predict(test_features_10)\n",
        "primary_accuracy = accuracy_score(test_labels, primary_predictions)\n",
        "print(f'Primary Forest Model Accuracy: {primary_accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9D8mDJYlmdC"
      },
      "source": [
        "#Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdrJPc5nlqAw"
      },
      "source": [
        "Primary Forest Model Accuracy: 0.9907\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lUko3jxd86_"
      },
      "source": [
        "# Step 3-2: Select Top 100 Trees\n",
        "We can select the top 100 trees based on feature importance scores provided by the Primary Forest model. Trees that contribute most to the model's accuracy are selected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5Ab3rB4Ed-z4"
      },
      "outputs": [],
      "source": [
        "# Get the feature importance scores from the primary forest\n",
        "importances = primary_forest.feature_importances_\n",
        "\n",
        "# Sort the trees by importance\n",
        "indices = np.argsort(importances)[-100:]\n",
        "\n",
        "# Extract the top 100 trees\n",
        "top_trees = [primary_forest.estimators_[i] for i in indices]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMfc_sFLeJMY"
      },
      "source": [
        "# Step 3-3: Create PF with Top 100 Trees and Evaluate\n",
        "Now we create a new forest using these top 100 trees and evaluate its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeJ6SsRgeL-x",
        "outputId": "43181f43-29ab-403d-e7c6-884935e9caaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PF Model Accuracy: 0.9905\n",
            "PF Model Precision: 0.9904, Recall: 0.9903, F1 Score: 0.9904\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize a new RF model with top 100 trees\n",
        "pf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Manually set the top 100 trees (estimators)\n",
        "pf_model.estimators_ = top_trees\n",
        "\n",
        "# Train the PF model on the top 100 trees\n",
        "pf_model.fit(train_features_10, train_labels)\n",
        "\n",
        "# Evaluate the PF model\n",
        "pf_predictions = pf_model.predict(test_features_10)\n",
        "pf_accuracy = accuracy_score(test_labels, pf_predictions)\n",
        "pf_precision = precision_score(test_labels, pf_predictions, average='macro')\n",
        "pf_recall = recall_score(test_labels, pf_predictions, average='macro')\n",
        "pf_f1 = f1_score(test_labels, pf_predictions, average='macro')\n",
        "\n",
        "print(f'PF Model Accuracy: {pf_accuracy:.4f}')\n",
        "print(f'PF Model Precision: {pf_precision:.4f}, Recall: {pf_recall:.4f}, F1 Score: {pf_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_A70dYNmoR4"
      },
      "source": [
        "# output:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2XGoKoWmmk5"
      },
      "source": [
        "PF Model Accuracy: 0.9905\n",
        "PF Model Precision: 0.9904, Recall: 0.9903, F1 Score: 0.9904\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKpRN5yGlyzp"
      },
      "source": [
        "# Conclusion\n",
        "Our results are impressive and demonstrate the effectiveness of both methodologies in achieving high performance on the MNIST dataset:\n",
        "\n",
        "# CNN + RF (100 Trees)\n",
        "\n",
        "Accuracy: 99.05%\n",
        "\n",
        "Precision: 99.04%\n",
        "\n",
        "Recall: 99.03%\n",
        "\n",
        "F1 Score: 99.04%\n",
        "\n",
        "# CNN + RF + RandomizedSearchCV\n",
        "\n",
        "Accuracy: 99.01%\n",
        "\n",
        "Precision: 99.00%\n",
        "\n",
        "Recall: 98.99%\n",
        "\n",
        "F1 Score: 98.99%\n",
        "\n",
        "# CNN + PF (100 Professional Trees)\n",
        "\n",
        "Primary Forest (2000 trees) Accuracy: 99.07%\n",
        "\n",
        "PF Model (100 Trees) Accuracy: 99.05%\n",
        "\n",
        "Precision: 99.04%\n",
        "\n",
        "Recall: 99.03%\n",
        "\n",
        "F1 Score: 99.04%\n",
        "\n",
        "These are excellent results, especially considering the complexity and challenges associated with the MNIST dataset. Achieving near world-class performance (99.3% to 99.4%) shows that our approach, CNN + PF (consisting of only 100 Professional Trees), is robust and competitive. Remarkably, this method achieves the same performance as a Random Forest consisting of 2000 trees but with only 100 trees, demonstrating its efficiency, robustness, and scalability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjlPek48oyOS"
      },
      "source": [
        "#step 4:\n",
        "#Creating and Evaluating PF Models with Different Numbers of Trees\n",
        "# Step 4-1: Create PF with 75 Trees and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7cZntX4pISp",
        "outputId": "7464a281-957e-4308-b132-04805399d41d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PF Model (75 Trees) Accuracy: 0.9903\n",
            "PF Model (75 Trees) Precision: 0.9902, Recall: 0.9901, F1 Score: 0.9902\n"
          ]
        }
      ],
      "source": [
        "# Select the top 75 trees based on previous selection criteria\n",
        "top_75_trees = [primary_forest.estimators_[i] for i in indices[-75:]]\n",
        "\n",
        "# Initialize a new RF model with top 75 trees\n",
        "pf_model_75 = RandomForestClassifier(n_estimators=75, random_state=42)\n",
        "\n",
        "# Manually set the top 75 trees (estimators)\n",
        "pf_model_75.estimators_ = top_75_trees\n",
        "\n",
        "# Train the PF model on the top 75 trees\n",
        "pf_model_75.fit(train_features_10, train_labels)\n",
        "\n",
        "# Evaluate the PF model\n",
        "pf_predictions_75 = pf_model_75.predict(test_features_10)\n",
        "pf_accuracy_75 = accuracy_score(test_labels, pf_predictions_75)\n",
        "pf_precision_75 = precision_score(test_labels, pf_predictions_75, average='macro')\n",
        "pf_recall_75 = recall_score(test_labels, pf_predictions_75, average='macro')\n",
        "pf_f1_75 = f1_score(test_labels, pf_predictions_75, average='macro')\n",
        "\n",
        "print(f'PF Model (75 Trees) Accuracy: {pf_accuracy_75:.4f}')\n",
        "print(f'PF Model (75 Trees) Precision: {pf_precision_75:.4f}, Recall: {pf_recall_75:.4f}, F1 Score: {pf_f1_75:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JglavapXE-p3"
      },
      "source": [
        "# output 4-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYNqDDLjE6kX"
      },
      "source": [
        "PF Model (75 Trees) Accuracy: 0.9903\n",
        "PF Model (75 Trees) Precision: 0.9902, Recall: 0.9901, F1 Score: 0.9902\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTJsX8D0pYBh"
      },
      "source": [
        "# Step 4-2: Create PF with 50 Trees and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCaey8lDpQdy",
        "outputId": "8df96ebb-9564-43da-f691-29800191bba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PF Model (50 Trees) Accuracy: 0.9905\n",
            "PF Model (50 Trees) Precision: 0.9904, Recall: 0.9903, F1 Score: 0.9904\n"
          ]
        }
      ],
      "source": [
        "# Select the top 50 trees based on previous selection criteria\n",
        "top_50_trees = [primary_forest.estimators_[i] for i in indices[-50:]]\n",
        "\n",
        "# Initialize a new RF model with top 50 trees\n",
        "pf_model_50 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Manually set the top 50 trees (estimators)\n",
        "pf_model_50.estimators_ = top_50_trees\n",
        "\n",
        "# Train the PF model on the top 50 trees\n",
        "pf_model_50.fit(train_features_10, train_labels)\n",
        "\n",
        "# Evaluate the PF model\n",
        "pf_predictions_50 = pf_model_50.predict(test_features_10)\n",
        "pf_accuracy_50 = accuracy_score(test_labels, pf_predictions_50)\n",
        "pf_precision_50 = precision_score(test_labels, pf_predictions_50, average='macro')\n",
        "pf_recall_50 = recall_score(test_labels, pf_predictions_50, average='macro')\n",
        "pf_f1_50 = f1_score(test_labels, pf_predictions_50, average='macro')\n",
        "\n",
        "print(f'PF Model (50 Trees) Accuracy: {pf_accuracy_50:.4f}')\n",
        "print(f'PF Model (50 Trees) Precision: {pf_precision_50:.4f}, Recall: {pf_recall_50:.4f}, F1 Score: {pf_f1_50:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQjNE_uFFKdv"
      },
      "source": [
        "#Output 4-2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH9SgpAvFOfY"
      },
      "source": [
        "PF Model (50 Trees) Accuracy: 0.9905\n",
        "PF Model (50 Trees) Precision: 0.9904, Recall: 0.9903, F1 Score: 0.9904\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvsuHtR1pl1h"
      },
      "source": [
        "# Step 4-3: Create PF with 25 Trees and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nDsosN7pyXK",
        "outputId": "657dd8f1-e823-4bb6-af02-fcd3654d0cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PF Model (25 Trees) Accuracy: 0.9904\n",
            "PF Model (25 Trees) Precision: 0.9903, Recall: 0.9902, F1 Score: 0.9903\n"
          ]
        }
      ],
      "source": [
        "# Select the top 25 trees based on previous selection criteria\n",
        "top_25_trees = [primary_forest.estimators_[i] for i in indices[-25:]]\n",
        "\n",
        "# Initialize a new RF model with top 25 trees\n",
        "pf_model_25 = RandomForestClassifier(n_estimators=25, random_state=42)\n",
        "\n",
        "# Manually set the top 25 trees (estimators)\n",
        "pf_model_25.estimators_ = top_25_trees\n",
        "\n",
        "# Train the PF model on the top 25 trees\n",
        "pf_model_25.fit(train_features_10, train_labels)\n",
        "\n",
        "# Evaluate the PF model\n",
        "pf_predictions_25 = pf_model_25.predict(test_features_10)\n",
        "pf_accuracy_25 = accuracy_score(test_labels, pf_predictions_25)\n",
        "pf_precision_25 = precision_score(test_labels, pf_predictions_25, average='macro')\n",
        "pf_recall_25 = recall_score(test_labels, pf_predictions_25, average='macro')\n",
        "pf_f1_25 = f1_score(test_labels, pf_predictions_25, average='macro')\n",
        "\n",
        "print(f'PF Model (25 Trees) Accuracy: {pf_accuracy_25:.4f}')\n",
        "print(f'PF Model (25 Trees) Precision: {pf_precision_25:.4f}, Recall: {pf_recall_25:.4f}, F1 Score: {pf_f1_25:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5pwp-aXFYLX"
      },
      "source": [
        "# Output 4-3:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK9sg7ouFdYn"
      },
      "source": [
        "PF Model (25 Trees) Accuracy: 0.9904\n",
        "PF Model (25 Trees) Precision: 0.9903, Recall: 0.9902, F1 Score: 0.9903\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et0fUA_z_BP9"
      },
      "source": [
        "# Step 4-4: Create PF with 10 Trees and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl0slN8f_H-m",
        "outputId": "a08a0189-3b58-4210-a157-a9be4365b404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PF Model (10 Trees) Accuracy: 0.9902\n",
            "PF Model (10 Trees) Precision: 0.9900, Recall: 0.9901, F1 Score: 0.9901\n"
          ]
        }
      ],
      "source": [
        "# Select the top 10 trees based on previous selection criteria\n",
        "top_10_trees = [primary_forest.estimators_[i] for i in indices[-10:]]\n",
        "\n",
        "# Initialize a new RF model with top 25 trees\n",
        "pf_model_10 = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "\n",
        "# Manually set the top 25 trees (estimators)\n",
        "pf_model_10.estimators_ = top_10_trees\n",
        "\n",
        "# Train the PF model on the top 25 trees\n",
        "pf_model_10.fit(train_features_10, train_labels)\n",
        "\n",
        "# Evaluate the PF model\n",
        "pf_predictions_10 = pf_model_10.predict(test_features_10)\n",
        "pf_accuracy_10 = accuracy_score(test_labels, pf_predictions_10)\n",
        "pf_precision_10 = precision_score(test_labels, pf_predictions_10, average='macro')\n",
        "pf_recall_10 = recall_score(test_labels, pf_predictions_10, average='macro')\n",
        "pf_f1_10 = f1_score(test_labels, pf_predictions_10, average='macro')\n",
        "\n",
        "print(f'PF Model (10 Trees) Accuracy: {pf_accuracy_10:.4f}')\n",
        "print(f'PF Model (10 Trees) Precision: {pf_precision_10:.4f}, Recall: {pf_recall_10:.4f}, F1 Score: {pf_f1_10:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AkYDLV3FmCP"
      },
      "source": [
        "# Output 4-4:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNBfRE8CFqfH"
      },
      "source": [
        "PF Model (10 Trees) Accuracy: 0.9902\n",
        "PF Model (10 Trees) Precision: 0.9900, Recall: 0.9901, F1 Score: 0.9901\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPuEaSxW_6C-"
      },
      "source": [
        "# Step 4-5: Create PF with 5 Trees and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at_0lsFt_9QP",
        "outputId": "6e6f4140-c5c6-43c1-d3c0-875b6944512b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PF Model (5 Trees) Accuracy: 0.9900\n",
            "PF Model (5 Trees) Precision: 0.9899, Recall: 0.9899, F1 Score: 0.9899\n"
          ]
        }
      ],
      "source": [
        "# Select the top 5 trees based on previous selection criteria\n",
        "top_5_trees = [primary_forest.estimators_[i] for i in indices[-5:]]\n",
        "\n",
        "# Initialize a new RF model with top 25 trees\n",
        "pf_model_5 = RandomForestClassifier(n_estimators=5, random_state=42)\n",
        "\n",
        "# Manually set the top 25 trees (estimators)\n",
        "pf_model_5.estimators_ = top_5_trees\n",
        "\n",
        "# Train the PF model on the top 25 trees\n",
        "pf_model_5.fit(train_features_10, train_labels)\n",
        "\n",
        "# Evaluate the PF model\n",
        "pf_predictions_5 = pf_model_5.predict(test_features_10)\n",
        "pf_accuracy_5 = accuracy_score(test_labels, pf_predictions_5)\n",
        "pf_precision_5 = precision_score(test_labels, pf_predictions_5, average='macro')\n",
        "pf_recall_5 = recall_score(test_labels, pf_predictions_5, average='macro')\n",
        "pf_f1_5 = f1_score(test_labels, pf_predictions_5, average='macro')\n",
        "\n",
        "print(f'PF Model (5 Trees) Accuracy: {pf_accuracy_5:.4f}')\n",
        "print(f'PF Model (5 Trees) Precision: {pf_precision_5:.4f}, Recall: {pf_recall_5:.4f}, F1 Score: {pf_f1_5:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7MRmripFz4I"
      },
      "source": [
        "# output 4-5:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZpFiGTaF3_v"
      },
      "source": [
        "PF Model (5 Trees) Accuracy: 0.9900\n",
        "PF Model (5 Trees) Precision: 0.9899, Recall: 0.9899, F1 Score: 0.9899\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee26ZVqyp0mh"
      },
      "source": [
        "# Conclusion for Part 4\n",
        "The results of creating and evaluating PF models with different numbers of trees are impressive and insightful. Here's a summary of the performance metrics for each configuration:\n",
        "\n",
        "# PF Model (100 Trees)\n",
        "\n",
        "Accuracy: 99.05%\n",
        "\n",
        "Precision: 99.04%\n",
        "\n",
        "Recall: 99.03%\n",
        "\n",
        "F1 Score: 99.04%\n",
        "\n",
        "# PF Model (75 Trees)\n",
        "\n",
        "Accuracy: 99.03%\n",
        "\n",
        "Precision: 99.02%\n",
        "\n",
        "Recall: 99.01%\n",
        "\n",
        "F1 Score: 99.02%\n",
        "\n",
        "# PF Model (50 Trees)\n",
        "\n",
        "Accuracy: 99.05%\n",
        "\n",
        "Precision: 99.04%\n",
        "\n",
        "Recall: 99.03%\n",
        "\n",
        "F1 Score: 99.04%\n",
        "\n",
        "# PF Model (25 Trees)\n",
        "\n",
        "Accuracy: 99.04%\n",
        "\n",
        "Precision: 99.03%\n",
        "\n",
        "Recall: 99.02%\n",
        "\n",
        "F1 Score: 99.03%\n",
        "\n",
        "# PF Model (10 Trees)\n",
        "\n",
        "Accuracy: 99.02%\n",
        "\n",
        "Precision: 99.00%\n",
        "\n",
        "Recall: 99.01%\n",
        "\n",
        "F1 Score: 99.01%\n",
        "\n",
        "# PF Model (5 Trees)\n",
        "\n",
        "Accuracy: 99.00%\n",
        "\n",
        "Precision: 98.99%\n",
        "\n",
        "Recall: 98.99%\n",
        "\n",
        "F1 Score: 98.99%\n",
        "\n",
        "These results show that even with a reduced number of trees, the PF models maintain high performance and robustness. Notably, the PF Model with 50 trees achieves the highest accuracy, precision, recall, and F1 score, making it an optimal choice in terms of balancing accuracy, efficiency, and scalability.\n",
        "\n",
        "Remarkably, the PF models with 75, 50, and even 25 trees surpass the performance of the initial 2000-tree Random Forest model, demonstrating that a smaller, well-selected ensemble of trees can be both effective and efficient. This highlights the power of the PF methodology in creating highly performant models with fewer resources.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMy4wvi-QmWL"
      },
      "source": [
        "## Additionally, it is noteworthy that the performance of the PF model with only 5 trees is better than that of the Random Forest model with 100 trees. This is very important as it showcases the powerful capability of the PF methodology to create a very tiny and scalable model, making it ideal for traditional usages such as IoT applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wa_qtWsQxl3"
      },
      "source": [
        "Overall, these findings indicate that the CNN + PF approach is robust, scalable, and competitive, achieving near world-class performance with a significantly reduced number of trees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOECj-1R94jT"
      },
      "source": [
        "## It’s important to note that we can achieve even higher performance by utilizing more advanced CNN models. Considering that the Test Accuracy of the LeNet-5 CNN model is 99.03%, we used this accuracy as a basis to feed into our RF and PF models. By employing better CNN architectures, there is potential to further enhance the overall performance of the combined models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N610fR2Q1pZ"
      },
      "source": [
        "# This makes it an excellent choice for real-world applications where computational efficiency and resource utilization are critical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fckc7EYNS4db"
      },
      "source": [
        "# License\n",
        "##This project is licensed under the MIT License - see the LICENSE file for details.\n",
        "\n",
        "##© 2024 Ali M Shafiei. All rights reserved."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
